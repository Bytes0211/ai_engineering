# Course Notes

## Table of Contents

- [Agentic AI](#agentic-ai)
  - [What Agentic AI Means](#-what-agentic-ai-means)
  - [How Agentic AI Works](#-how-agentic-ai-works)
  - [Agentic AI vs. Generative AI](#-agentic-ai-vs-generative-ai)
  - [Real-World Examples](#ï¸-real-world-examples)
  - [Why Agentic AI Matters](#-why-agentic-ai-matters)
- [AI Model Overview](#ai-model-overview)
  - [AI Model Taxonomy Hierarchy](#-ai-model-taxonomy-hierarchy)
  - [Frontier LLMs vs. Foundation LLMs](#-frontier-llms-vs-foundation-llms)
    - [What Are Foundation Models?](#-what-are-foundation-models)
    - [What Are Frontier Models?](#-what-are-frontier-models)
    - [The Core Difference](#-the-core-difference)
    - [Quick Comparison Table](#-quick-comparison-table)
    - [Foundation and Frontier Models](#-foundation-and-frontier-models)
  - [Reasoning Models vs. Agentic Models](#-reasoning-models-vs-agentic-models)
    - [Reasoning Models](#-reasoning-models)
    - [Agentic Models (or Agentic Systems)](#-agentic-models-or-agentic-systems)
    - [The Cleanest Distinction](#-the-cleanest-distinction)
    - [How They Relate](#-how-they-relate)
    - [Why People Confuse Them](#-why-people-confuse-them)
  - [Model Use Cases](#model-use-cases)
    - [1. Chat Interfaces](#-1-chat-interfaces)
    - [2. Cloud APIs](#ï¸-2-cloud-apis)
    - [3. Direct Inference with Open-Source Models](#ï¸-3-direct-inference-with-opensource-models)
    - [Additional Ways to Use Models (Often Overlooked)](#-additional-ways-to-use-models-often-overlooked)
  - [Model Usage Summary Table](#-model-usage-summary-table)
- [Chat Completions API â€” What Is It](#-chat-completions-api--what-is-it)
  - [How Chat Completions Work](#-how-chat-completions-work)
  - [Example Request (from Azure's documentation)](#-example-request-from-azures-documentation)
  - [Message Roles](#-message-roles)
  - [Key Features](#ï¸-key-features)
  - [Endpoints (from DeepWiki)](#-endpoints-from-deepwiki)
  - [Chat Completions Summary Table](#-chat-completions-summary-table)
- [What a Transformer Is (in AI)](#-what-a-transformer-is-in-ai)
  - [Key Concepts Inside a Transformer](#-key-concepts-inside-a-transformer)
  - [Why Transformers Matter](#-why-transformers-matter)
  - [Transformer vs. Older Models](#-transformer-vs-older-models)
  - [Clean Mental Model](#-clean-mental-model-1)
- [Tokens (AI / Transformers)](#-tokens-ai--transformers)
  - [Why Tokens Exist](#-why-tokens-exist)
  - [Examples of Tokenization](#-examples-of-tokenization)
  - [How Tokens Fit Into Transformers](#-how-tokens-fit-into-transformers-from-your-previous-question)
  - [How Many Characters Is a Token?](#-how-many-characters-is-a-token)
  - [Clean Mental Model](#-clean-mental-model)
- [Parameters](#-parameters)
  - [What Parameters Look Like](#-what-parameters-look-like)
  - [Why Parameters Matter](#-why-parameters-matter)
  - [Simple Example](#-simple-example)
  - [Clean Mental Model](#-clean-mental-model-2)
- [Context Window](#context-window)
  - [What an AI Context Window Is](#-what-an-ai-context-window-is)
  - [What the Context Window Controls](#-what-the-context-window-controls)
  - [Why Context Window Matters in Practice](#-why-context-window-matters-in-practice)
  - [Clean Mental Model](#-clean-mental-model-3)
  - [Context Window Comparison Across Major Models](#-context-window-comparison-across-major-models)
  - [Which Models Handle Long Context Best?](#-which-models-handle-long-context-best)
- [What Internal Reasoning Tokens Are](#-what-internal-reasoning-tokens-are)
  - [Why They Exist](#-why-they-exist)
  - [How Internal Reasoning Tokens Flow Through the Model](#-how-internal-reasoning-tokens-flow-through-the-model)
  - [Where They Live in the Context Window](#ï¸-where-they-live-in-the-context-window)
  - [They Enable Multi-Pass Thinking](#-they-enable-multi-pass-thinking)
  - [Why You Don't See Them](#-why-you-dont-see-them)
  - [Clean Mental Model](#-clean-mental-model-4)

## Agentic AI

Agentic AI is one of the most important shifts happening in AI right now, and the search results you triggered give a very clear foundation. Iâ€™ll synthesize them into a crisp, practical explanation you can use in engineering, architecture, or strategy discussions.

---

### ğŸ¤– What *Agentic AI* Means  

Agentic AI refers to **AI systems that can plan, reason, and take actions autonomously**â€”not just generate content. Instead of waiting for a prompt and producing a single output, an agentic system can:

- Understand goals  
- Break them into steps  
- Choose tools or APIs  
- Execute actions  
- Reflect and improve  

IBM describes agentic AI as systems that â€œaccomplish a specific goal with limited supervisionâ€ and exhibit autonomy, goalâ€‘driven behavior, and adaptability.  
Google Cloud emphasizes that agentic AI can â€œset goals, plan, and execute tasks with minimal human interventionâ€.  
Microsoft (via the University of Cincinnati summary) defines it as AI that â€œplans, reasons and acts to complete tasks with minimal human oversightâ€.

---

### ğŸ§© How Agentic AI Works  

Across the sources, the core loop looks like this:

#### 1. **Perception**  

Gather information from text, sensors, APIs, databases, or user input.

#### 2. **Reasoning**  

Use an LLM to interpret context, constraints, and goals.

#### 3. **Planning**  

Break the goal into steps and choose a strategy.

#### 4. **Action**  

Call tools, APIs, or external systems to execute tasks.

#### 5. **Reflection**  

Evaluate results and adjust future actions.

This loop is what makes agentic systems feel â€œaliveâ€ compared to traditional promptâ€‘response models.

---

### ğŸ†š Agentic AI vs. Generative AI  

| Generative AI | Agentic AI |
|---------------|------------|
| Produces content (text, code, images) | Achieves goals through actions |
| Requires explicit prompts | Operates with autonomy and initiative |
| No memory of longâ€‘term objectives | Maintains goals and multiâ€‘step plans |
| Cannot act on the world | Can call tools, APIs, and systems |

Generative AI is *creative*.  
Agentic AI is *productive*.

---

### ğŸ› ï¸ Realâ€‘World Examples  

The search results highlight several concrete examples:

#### âœˆï¸ Travel booking  

An agent can plan a trip, compare prices, and book flights/hotels automatically.

#### ğŸ“… Scheduling  

Parse emails, find availability, and schedule meetings without human intervention.

#### ğŸ§¾ Document workflows  

Review, classify, or extract data and then take followâ€‘up actions (e.g., file, notify, escalate).

#### ğŸ›’ Eâ€‘commerce automation  

Monitor inventory, adjust pricing, or trigger supplyâ€‘chain actions.

#### ğŸ§‘â€ğŸ’¼ Enterprise automation  

Multiâ€‘step workflows like onboarding, approvals, or compliance checks.

---

### ğŸ§  Why Agentic AI Matters  

Agentic AI is the bridge between **LLMs** and **real automation**.

It enables systems that can:

- Work continuously toward goals  
- Handle ambiguity  
- Adapt to changing conditions  
- Integrate with enterprise systems  
- Reduce human supervision  

[ToC](#table-of-contents)

## AI Model Overview

### ğŸ§¬ AI Model Taxonomy Hierarchy

```txt
AI Ecosystem
â”‚
â”œâ”€â”€ 1. Narrow / Taskâ€‘Specific Models
â”‚       â”œâ”€â”€ Spam Classifiers
â”‚       â”œâ”€â”€ Sentiment Models
â”‚       â”œâ”€â”€ Recommendation Models
â”‚       â””â”€â”€ Vision Classifiers
â”‚
â””â”€â”€ 2. Foundation Models  (Broad, Generalâ€‘Purpose)
        â”‚
        â”œâ”€â”€ 2.1 Base Foundation Models
        â”‚       â”œâ”€â”€ BERT
        â”‚       â”œâ”€â”€ CLIP
        â”‚       â”œâ”€â”€ Stable Diffusion
        â”‚       â”œâ”€â”€ Llama (base)
        â”‚       â”œâ”€â”€ Mistral (base)
        â”‚       â”œâ”€â”€ Qwen (base)
        â”‚       â””â”€â”€ Other Multimodal Base Models
        â”‚
        â”œâ”€â”€ 2.2 Fineâ€‘Tuned Foundation Models
        â”‚       â”œâ”€â”€ Llamaâ€‘3/4â€‘Instruct (Open Source)
        â”‚       â”œâ”€â”€ Mistralâ€‘Instruct (Open Source)
        â”‚       â”œâ”€â”€ Stable Diffusion XL Variants
        â”‚       â””â”€â”€ Domainâ€‘Specific Tuned Models
        â”‚
        â”œâ”€â”€ 2.3 Multimodal Models
        â”‚       â”œâ”€â”€ Gemini (Google DeepMind)
        â”‚       â””â”€â”€ GPTâ€‘4o (OpenAI)
        â”‚
        â”œâ”€â”€ 2.4 Reasoning Models  (Specialized Subset)
        â”‚       â”œâ”€â”€ OpenAI o1 / o3â€‘mini
        â”‚       â”œâ”€â”€ DeepSeekâ€‘R1
        â”‚       â”œâ”€â”€ QwQâ€‘32B
        â”‚       â”œâ”€â”€ Claude 3.7 Sonnet Thinking
        â”‚       â””â”€â”€ Gemini Flash Thinking
        â”‚
        â””â”€â”€ 2.5 Frontier Models  (Most Advanced Subset)
                â”œâ”€â”€ GPTâ€‘4 / GPTâ€‘4.1 Class [OpenAi]
                â”œâ”€â”€ Claude 3 (Opus, Sonnet, Haiku) [Anthropic]
                â”œâ”€â”€ Gemini Ultra [Google]
                â”œâ”€â”€ DeepSeekâ€‘V3 / R1 [DeepSeek]
                â””â”€â”€ xAI Grokâ€‘2 [X.ai]


Agentic Systems  (Built *on top of* Foundation + Reasoning Models)
â”‚
â”œâ”€â”€ Workflow Agents
â”œâ”€â”€ Research Agents
â”œâ”€â”€ RAG Agents (Retrievalâ€‘Augmented Agents)
â”œâ”€â”€ Multiâ€‘Agent Systems
â”œâ”€â”€ Taskâ€‘Oriented Copilots
â””â”€â”€ Autonomous Assistants

```

### ğŸ§  Frontier LLMs vs. Foundation LLMs  

The two terms sound similar, but they describe **different tiers of AI models**.

---

#### ğŸ§© What Are **Foundation Models**?

Foundation models are **large, generalâ€‘purpose models** trained on broad, diverse datasets and designed to be adapted to many downstream tasks.  
They include models like BERT, GPTâ€‘3, CLIP, Llama, and Mistral base models.

Key characteristics from the search results:  

- Trained on **broad, massive datasets**  
- Serve as **base layers** for fineâ€‘tuning or prompting  
- Can be multimodal (text, images, audio, video)  
- Represent the **core infrastructure** of modern AI systems

Think of them as the *trunk* of the AI tree â€” general, flexible, and adaptable.

---

#### ğŸš€ What Are **Frontier Models**?

Frontier models are a **subset of foundation models**, but at the *cutting edge* of capability.  
They represent the **most advanced, highestâ€‘performing, nextâ€‘generation** models available.

Key characteristics from the search results:  

- Push the **boundaries of current AI capabilities**  
- Represent the **stateâ€‘ofâ€‘theâ€‘art** in performance and safety research  
- Often developed by top â€œfrontier labsâ€ like OpenAI, Anthropic, Google DeepMind  
- Exceed the capabilities of existing advanced models

Examples include GPTâ€‘4, Claude 3 Opus, Gemini Ultra â€” the models at the very top of the capability curve.

---

#### ğŸ§­ The Core Difference  

**All frontier models are foundation models, but not all foundation models are frontier models.**
So frontier models are a subset of foundation models

This is supported directly by the sources:

- Foundation models = broad, generalâ€‘purpose base models  
- Frontier models = the **most advanced** models that surpass current capabilities  
- Taxonomy places frontier models as a **higher tier** above foundation models

---

#### ğŸ“Š Quick Comparison Table

| Feature | Foundation Models | Frontier Models |
|--------|-------------------|-----------------|
| Purpose | Generalâ€‘purpose base models | Push the limits of AI capability |
| Scope | Broad, adaptable | Most advanced subset of foundation models |
| Examples | BERT, CLIP, Llama, Mistral | GPTâ€‘4, Claude 3, Gemini Ultra |
| Training Data | Large, diverse datasets | Same, but with extreme scale and optimization |
| Role | Infrastructure for downstream tasks | Cuttingâ€‘edge research and topâ€‘tier performance |
| Who Builds Them | Many labs (Meta, Mistral, etc.) | â€œFrontier labsâ€ (OpenAI, Anthropic, Google DeepMind) |

#### ğŸ“Š Foundation and Frontier Models

##### ğŸ§± **Foundation Models**

These are large, generalâ€‘purpose models trained on broad data and adaptable to many downstream tasks.

| Model | Type | Open Source | Company / Lab |
|-------|------|-------------|----------------|
| **BERT** | Foundation | Yes | Google |
| **CLIP** | Foundation | Yes | OpenAI |
| **GPT-OSS** | Foundation | Yes | OpenAI |
| **GPTâ€‘3** | Foundation | No | OpenAI |
| **Llama 2 / Llama 3** | Foundation LLM | Yes | Meta |
| **Mistral 7B / Mixtral** | Foundation LLM | Yes | Mistral AI |
| **Qwen - 2** | Foundation LLM | Yes | Alibaba Cloud |
| **Gemma** | Foundation LLM | Yes | Google |
| **Phi** | Foundation LLM | Yes | Microsoft |
| **DeepSeek** | Foundation LLM | Yes | DeepSeek AI |
| **Stable Diffusion** | Foundation (image) | Yes | Stability AI |
| **DALLâ€‘E** | Foundation (image) | No | OpenAI |
| **Flamingo** | Foundation (visionâ€‘language) | No | DeepMind |
| **MusicGen** | Foundation (audio) | Yes | Meta |
| **RTâ€‘2** | Foundation (robotics) | No | Google DeepMind |

##### ğŸš€ **Frontier Models**

These are the **most advanced, cuttingâ€‘edge** models that exceed the capabilities of existing systems.

| Model | Type | Open Source | Company / Lab |
|-------|------|-------------|----------------|
| **GPTâ€‘4 / GPTâ€‘4.1 / GPTâ€‘5â€‘class** | Frontier LLM | No | OpenAI |
| **Claude 3 (Opus, Sonnet, Haiku)** | Frontier LLM | No | Anthropic |
| **Gemini Ultra** | Frontier LLM | No | Google DeepMind |
| **DeepSeekâ€‘V3 / DeepSeekâ€‘R1** | Frontier LLM | Partially (R1â€‘Distill) | DeepSeek |
| **xAI Grokâ€‘2** | Frontier LLM | Partially | xAI |
| **Frontierâ€‘scale multimodal models** (e.g., Gemini Ultra Vision, GPTâ€‘4oâ€‘class) | Frontier | No | OpenAI / Google DeepMind |

---

### ğŸ§  **Reasoning Models vs. Agentic Models**

#### ğŸ§© **Reasoning Models**

A *reasoning model* is an LLM that has been optimized to think more deeply, follow multiâ€‘step logic, and solve complex problems.

These models focus on:

- Chainâ€‘ofâ€‘thought reasoning  
- Planning and decomposition  
- Math and logic  
- Longâ€‘horizon problem solving  
- Selfâ€‘correction  

Examples:

- OpenAI o1 / o3â€‘mini  
- DeepSeekâ€‘R1  
- QwQâ€‘32B  
- Gemini 2.0 Flash Thinking  
- Claude 3.7 Sonnet Thinking  

**Key idea:**  
A reasoning model is still *just a model*. It doesnâ€™t act on the world by itself.

---

#### ğŸ¤– **Agentic Models (or Agentic Systems)**

An *agentic model* is not a model at all â€” itâ€™s a **system** built around a model.

Agentic systems add:

- Tool use  
- Memory  
- Planning loops  
- Environment interaction  
- Autonomy  
- Multiâ€‘step execution  
- Error recovery  
- Goalâ€‘directed behavior  

Examples:

- AI agents that book travel  
- Workflowâ€‘executing copilots  
- Multiâ€‘agent systems  
- Agentic RAG  
- Autonomous research agents  
- Assistants that call APIs, run code, browse, schedule, etc.

**Key idea:**  
Agentic systems use LLMs (often reasoning models) as the *brain*, but the agent is the whole machine â€” not the model.

---

#### ğŸ§­ **The Cleanest Distinction**

| Concept | What It Is | What It Does |
|--------|-------------|---------------|
| **Reasoning Model** | A type of LLM | Thinks better |
| **Agentic Model/System** | A system built around an LLM | Acts, decides, uses tools |

---

#### ğŸ”— **How They Relate**

Reasoning models are **ingredients**.  
Agentic systems are **recipes**.

A reasoning model can power an agent, but it is **not** an agent by itself.

Think of it like this:

- A reasoning model is a brilliant mathematician.  
- An agent is a mathematician who also has a laptop, internet access, a calendar, and the ability to execute tasks.

---

#### ğŸ§  **Why People Confuse Them**

Modern reasoning models (like o1 or DeepSeekâ€‘R1) *feel* more agentâ€‘like because they:

- Plan  
- Reflect  
- Break tasks into steps  
- Produce structured tool calls  

But they still donâ€™t act autonomously without an agent framework around them.

---

### Model Use Cases

The **three primary ways to use AI models**, plus **additional modes** that most teams overlook. Iâ€™ll keep it crisp but meaningful so you can plug this directly into architecture docs or onboarding materials.

---

#### ğŸ§  1. **Chat Interfaces**

These are conversational UIs where the model interacts with users in natural language.

##### What this means  

- A user types or speaks a prompt  
- The model responds conversationally  
- Often includes memory, context windows, and toolâ€‘use  
- Usually hosted by a platform (Copilot, ChatGPT, Claude, Gemini, etc.)

##### Common Use Cases  

- Customer support assistants  
- Internal knowledge assistants  
- Coding copilots  
- Document Q&A  
- Brainstorming, writing, summarization  
- Agentic workflows (multiâ€‘step reasoning + tool calls)

##### When to use  

- You need **humanâ€‘inâ€‘theâ€‘loop** interaction  
- You want rapid prototyping  
- You donâ€™t want to manage infrastructure  
- You need a UI for nonâ€‘technical users  

---

### â˜ï¸ 2. **Cloud APIs**

Models accessed programmatically through an API endpoint (e.g., Bedrock, OpenAI, Anthropic, Azure OpenAI, Google Vertex).

#### How Clouod APIs Work

- Your application sends a request to a cloud endpoint  
- The model returns text, embeddings, images, or structured output  
- You pay per token or per request  
- No infrastructure to manage

#### Cloud API Use Cases  

- RAG pipelines  
- Chatbots embedded in apps  
- Automated document processing  
- Code generation services  
- Workflow automation  
- Multimodal apps (vision, audio, video)

#### When to use Cloud APIs

- You need **scalability**  
- You want **enterpriseâ€‘grade reliability**  
- You need **highâ€‘end frontier models**  
- You donâ€™t want to host models yourself  

---

### ğŸ–¥ï¸ 3. **Direct Inference with Openâ€‘Source Models**

Running models locally or on your own servers using frameworks like **Ollama, Hugging Face, vLLM, llama.cpp, TensorRTâ€‘LLM**, etc.

#### How Direct Inference Work

- You download the model weights  
- You run inference on your hardware (CPU/GPU)  
- You control performance, privacy, and cost  
- You can fineâ€‘tune or quantize models

#### Direct Inference Common Use Cases  

- Onâ€‘prem or airâ€‘gapped environments  
- Privacyâ€‘sensitive workloads  
- Custom fineâ€‘tuning  
- Edge devices (Jetson, mobile, embedded)  
- Costâ€‘optimized inference at scale  
- Hybrid RAG (local + cloud fallback)

#### When to use Direct Inference

- You need **full control**  
- You want **zero perâ€‘token cost**  
- You need **offline or private inference**  
- You want to customize or extend the model  

---

### â• Additional Ways to Use Models (Often Overlooked)

#### 4. **Model Embeddings**

Using models to convert text, images, or documents into vector embeddings.

##### Model Embedding Use Cases  

- Semantic search  
- RAG retrieval  
- Clustering and classification  
- Recommendation systems  
- Similarity detection  
- Fraud detection  

---

#### 5. **Fineâ€‘Tuning / Continued Training**

Training a model on domainâ€‘specific data to improve performance.

##### Fine-Tuning / Continued Training Use Cases  

- Industryâ€‘specific chatbots  
- Legal/medical assistants  
- Codeâ€‘baseâ€‘specific copilots  
- Product catalog enrichment  
- Custom reasoning tasks  

---

#### 6. **Agents and Toolâ€‘Using Systems**

Models that can call APIs, run code, browse the web, or orchestrate workflows.

##### Agents and Tool-Using Systems Use Cases  

- Automated research  
- Multiâ€‘step business processes  
- Travel booking  
- Scheduling  
- Data extraction + action  
- Enterprise automation  

---

#### 7. **Batch Processing Pipelines**

Running models over large datasets in bulk.

##### Batch Processsing Pipelines Use Cases  

- Document classification  
- Largeâ€‘scale summarization  
- Data labeling  
- Image/video analysis  
- ETL enrichment in data lakes  

---

#### 8. **Edge and Mobile Deployment**

Running small or quantized models on devices.

##### Edge and Mobile Depoyment Use Cases  

- Onâ€‘device assistants  
- Realâ€‘time vision (drones, robotics)  
- Offline translation  
- Privacyâ€‘preserving inference  

---

### ğŸ§­ Model Usage Summary Table

| Method | Description | Best For |
|--------|-------------|----------|
| **Chat Interfaces** | Humanâ€‘facing conversational UI | Support, ideation, copilots |
| **Cloud APIs** | Programmatic access to hosted models | Scalable apps, RAG, automation |
| **Direct Inference (Open Source)** | Run models locally/onâ€‘prem | Privacy, customization, cost control |
| **Embeddings** | Vector representations | Search, RAG, recommendations |
| **Fineâ€‘Tuning** | Domainâ€‘specific training | Specialized assistants |
| **Agents** | Models that act via tools | Automation, workflows |
| **Batch Processing** | Largeâ€‘scale offline inference | Document pipelines |
| **Edge Deployment** | Onâ€‘device inference | Robotics, mobile, offline apps |

---

[ToC](#table-of-contents)

## ğŸ’¬ Chat Completions API â€” What Is It

Code can be found in the `/projects/ai_engineering/chat_completions/`

The **Chat Completions API** is an endpoint used to generate model responses in a **chatâ€‘style format**, where the input is a list of messages and the output is a modelâ€‘generated message.

OpenAI describes it as an API that â€œgenerates a model response from a list of messages comprising a conversationâ€.

Azureâ€™s documentation reinforces that chat models are **optimized for conversational interfaces**, expecting input in a structured chat transcript format and returning a modelâ€‘written message.

DeepWiki adds that the Chat Completions API is the **messageâ€‘based interface** for text generation and supports streaming, tool calling, and structured outputs.

---

### ğŸ§© How Chat Completions Work  

You send a request containing:

- A **model** (e.g., `gpt-4o`)
- A **messages array** (system/developer/user messages)
- Optional parameters (temperature, max tokens, top_p, etc.)

The API returns:

- A **completion** containing the modelâ€™s next message  
- Metadata (id, usage, finish_reason, etc.)

---

### ğŸ§± Example Request (from Azureâ€™s documentation)

```python
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "Assistant is a large language model."},
        {"role": "user", "content": "Who were the founders of Microsoft?"}
    ]
)
```

This example is directly aligned with Azureâ€™s Chat Completions documentation.

---

### ğŸ§­ Message Roles  

The API supports several message types:

- **developer** (replaces system messages for newer models)  
- **system** (instructions for older models)  
- **user** (human input)  
- **assistant** (model output)

---

### âš™ï¸ Key Features  

According to the search results:

#### âœ”ï¸ Multiâ€‘turn conversation support  

The API is designed for chatâ€‘style interactions where messages accumulate over time.

#### âœ”ï¸ Supports text, images, and audio (depending on model)  

The messages array can contain different content types for multimodal models.

#### âœ”ï¸ Streaming responses  

The API can stream partial outputs in real time.

#### âœ”ï¸ Tool calling / function execution  

The API supports structured tool calls for automation workflows.

#### âœ”ï¸ Structured outputs  

You can enforce JSON schemas or typed outputs using structured output features.

---

### ğŸ§± Endpoints (from DeepWiki)

The Chat Completions resource supports:

- `POST /chat/completions` â€” create a new completion  
- `GET /chat/completions/{id}` â€” retrieve a stored completion  
- `POST /chat/completions/{id}` â€” update metadata  
- `DELETE /chat/completions/{id}/messages` â€” delete messages  
- `GET /chat/completions` â€” list completions  

These endpoints are documented in the DeepWiki reference.

---

### ğŸ“Š Chat Completions Summary Table

| Feature | Description | Source |
|--------|-------------|--------|
| Purpose | Generate model responses from chat messages |  |
| Input Format | Array of messages with roles |  |
| Optimized For | Conversational interfaces |  |
| Supports | Text, images, audio (modelâ€‘dependent) |  |
| Advanced Features | Streaming, tool calling, structured outputs |  |
| Endpoints | Create, retrieve, update, list, delete |  |

---

[ToC](#table-of-contents)

## ğŸ§  **What a Transformer Is (in AI)**  

A **Transformer** is the neuralâ€‘network architecture that unlocked the modern AI era. If you think of todayâ€™s LLMs as skyscrapers, the Transformer is the steel frame that makes them possible.

A **Transformer** is a deepâ€‘learning architecture designed to process sequences (like text, audio, or tokens) using a mechanism called **attention**.  
It was introduced in the 2017 paper *â€œAttention Is All You Needâ€* and replaced older sequence models like RNNs and LSTMs.

The core idea:

> Instead of reading text wordâ€‘byâ€‘word in order, a Transformer looks at **all words at once** and learns which ones matter most.

This ability to model relationships across long distances in text is what makes Transformers so powerful.

---

### ğŸ” **Key Concepts Inside a Transformer**

#### 1. **Selfâ€‘Attention**

The model learns how much each token should â€œpay attentionâ€ to every other token.

Example:  
In the sentence *â€œThe cat that chased the mouse was hungryâ€*,  
the word **â€œwasâ€** needs to attend to **â€œcatâ€**, not **â€œmouseâ€**.

Selfâ€‘attention lets the model figure that out automatically.

---

#### 2. **Multiâ€‘Head Attention**

Instead of one attention pattern, the model learns many in parallel.

Each â€œheadâ€ focuses on something different:

- syntax  
- longâ€‘range dependencies  
- semantic meaning  
- relationships between entities  

This is why Transformers understand context so well.

---

#### 3. **Positional Encoding**

Transformers donâ€™t read text sequentially, so they need a way to know **order**.

Positional encodings give each token a sense of:

- position  
- distance  
- relative ordering  

---

#### 4. **Stacked Layers**

Transformers are built by stacking many layers of:

- attention  
- feedâ€‘forward networks  
- normalization  

More layers â†’ deeper reasoning and richer representations.

---

### ğŸš€ **Why Transformers Matter**

Transformers enabled:

- **Large Language Models (LLMs)**  
  GPT, Claude, Gemini, Llama, Mistral, Qwen

- **Multimodal models**  
  GPTâ€‘4o, Gemini, CLIP, Flamingo

- **Diffusion models**  
  Stable Diffusion uses a Transformer backbone for text encoding

- **Speech models**  
  Whisper, AudioLM

Transformers are the foundation of nearly every frontier AI system today.

---

### ğŸ“Š **Transformer vs. Older Models**

| Model Type | Limitation | How Transformers Fix It |
|------------|------------|--------------------------|
| RNN | Slow, sequential | Parallel processing |
| LSTM | Struggles with long context | Global attention |
| CNN | Local patterns only | Longâ€‘range relationships |
| Transformer | None of the above | Scales to billions of parameters |

Transformers scale beautifully â€” thatâ€™s why LLMs can grow to 70B, 400B, or even more parameters.

---

### ğŸ§­ **Clean Mental Model**

A Transformer is like a room full of experts all reading the same sentence at once.  
Each expert focuses on a different relationship, and together they build a deep understanding of the text.

---

## ğŸ§  **Tokens (AI / Transformers)**  

A **token** is one of the smallest units of text that an AI model reads, processes, and predicts.  
If you imagine language as a stream of tiny building blocks, tokens are those blocks.

Theyâ€™re not exactly words â€” theyâ€™re **pieces** of words.

A **token** is a chunk of text (or audio, or image embedding) that a model converts into a numerical representation so it can understand and generate language.

Depending on the model, a token might be:

- a whole word  
- part of a word  
- a punctuation mark  
- a space  
- a subword like â€œingâ€, â€œpreâ€, â€œ##tionâ€  
- an emoji  
- a special symbol (like `<start>` or `<end>`)

Transformers donâ€™t operate on raw text â€” they operate on **tokens**, which are then turned into vectors.

---

### ğŸ” **Why Tokens Exist**  

Models need a consistent way to break text into manageable pieces.  
Tokens solve this by:

- reducing vocabulary size  
- handling rare words  
- supporting multiple languages  
- making training efficient  
- enabling models to generalize better

This is why modern tokenizers use **subword units** (like Byte Pair Encoding or SentencePiece).

---

### ğŸ§© **Examples of Tokenization**

#### Example 1 â€” Simple English sentence  

Text:  

```txt
Transformers are amazing!
```

Possible tokens:  

```txt
["Transform", "ers", "are", "amazing", "!"]
```

#### Example 2 â€” Word with unusual spelling  

Text:  

```txt
uncharacteristically
```

Tokens might be:  

```txt
["un", "character", "istic", "ally"]
```

#### Example 3 â€” Emoji  

```txt
"ğŸ”¥" â†’ ["ğŸ”¥"]
```

#### Example 4 â€” Spaces matter  

```
"hello" vs " hello"
```

These tokenize differently because leading spaces are part of the token.

---

### ğŸ§  **How Tokens Fit Into Transformers (from your previous question)**  

Transformers donâ€™t read text directly.  
They read **token embeddings**.

The flow looks like this:

```txt
Text â†’ Tokenizer â†’ Tokens â†’ Embeddings â†’ Transformer Layers â†’ Output Tokens â†’ Text
```

Tokens are the bridge between human language and the modelâ€™s internal math.

---

### ğŸ“ **How Many Characters Is a Token?**  

Thereâ€™s no fixed size, but a common rule of thumb:

- **1 token â‰ˆ 3â€“4 characters of English**
- **75 tokens â‰ˆ 1 paragraph**
- **1,000 tokens â‰ˆ 750 words**

This varies by language and tokenizer.

---

### ğŸ§­ **Clean Mental Model**  

A token is like a Lego brick.  
Words are built from tokens.  
Sentences are built from words.  
Transformers operate on the bricks, not the finished structure.

---

[ToC](#table-of-contents)

## ğŸ§  Parameters  

In AIâ€”especially in modern neural networks like Transformersâ€”**parameters are the internal numerical values the model learns during training**. Theyâ€™re the knobs, weights, and biases that determine how the model behaves, thinks, and responds.

A clean way to say it:

> **Parameters are the learned values inside a model that shape how it transforms input into output.**

Theyâ€™re not rules written by humans.  
Theyâ€™re patterns the model *discovers* from data.

Every parameter influences how strongly one piece of information affects another.

In a Transformer, parameters control things like:

- how much one token attends to another  
- how information flows through layers  
- how embeddings are transformed  
- how the model predicts the next token  

If you imagine the model as a giant mathematical machine, parameters are the dials that define its behavior.

---

### ğŸ”¢ What Parameters Look Like  

A parameter is just a numberâ€”usually a floatingâ€‘point value like:

```txt
0.1284
-0.0047
1.9321
```

A small model might have **millions** of these.  
Frontier models have **hundreds of billions**.

Each one is tiny and meaningless alone.  
Together, they encode the modelâ€™s entire â€œknowledgeâ€.

---

### ğŸ§© Why Parameters Matter  

Parameters determine:

- how well the model understands language  
- how coherent its responses are  
- how much reasoning it can perform  
- how much context it can use  
- how well it generalizes to new tasks  

More parameters â‰  always better, but they do enable richer representations.

---

### ğŸ§ª Simple Example  

Imagine a tiny neural network layer:

\[
\text{output} = W \cdot x + b
\]

- **W** (weights) = parameters  
- **b** (biases) = parameters  
- **x** = input  
- **output** = transformed representation  

During training, the model adjusts **W** and **b** to reduce error.

---

### ğŸ§­ Clean Mental Model  

Think of parameters as:

- the **memory** of the model  
- the **knowledge** it has absorbed  
- the **settings** that define how it processes information  
- the **internal wiring** that shapes its intelligence  

Theyâ€™re the reason a model can translate languages, write code, or solve math problemsâ€”without being explicitly programmed to do so.

---

## Context Window

The **AI context window** is one of the most important â€” and most misunderstood â€” concepts in modern language models. Once you grasp it, a lot of AI behavior suddenly makes sense.

---

### ğŸ§  **What an AI Context Window Is**

The **context window** is the maximum amount of information (tokens) an AI model can â€œhold in mindâ€ at once while generating a response.

Think of it as the modelâ€™s **working memory**.

- It includes your prompt  
- plus any previous messages  
- plus the modelâ€™s own internal reasoning tokens  
- plus the output it generates  

All of that must fit inside the window.

If the window is 128k tokens, the model can only consider 128k tokens of text at a time. Anything beyond that gets **forgotten**, truncated, or summarized.

---

### ğŸ” **What the Context Window Controls**

#### 1. **How much the model can remember in a conversation**

If you exceed the window, older messages fall out of memory.

#### 2. **How much text the model can analyze at once**

Large windows allow:

- long documents  
- multiâ€‘file codebases  
- entire research papers  
- long transcripts  

#### 3. **How well the model maintains coherence**

Bigger windows â†’ better longâ€‘range reasoning.

#### 4. **How much reasoning the model can perform internally**

Reasoning models (like o1â€‘style systems) use many internal tokens.  
These also count toward the window.

---

### ğŸ§© **Why Context Window Matters in Practice**

#### **A. Long conversations**

If you chat for hours, older parts may fall out of the window unless the system summarizes them.

#### **B. Document analysis**

If you upload a 200â€‘page PDF to a model with a 32k window, it canâ€™t read it all at once.

#### **C. Codebase understanding**

Large windows allow models to ingest entire repositories.

#### **D. Reasoning depth**

More window = more internal chainâ€‘ofâ€‘thought capacity.

---

### ğŸ§  **Clean Mental Model**

The context window is the modelâ€™s **shortâ€‘term memory**.

- Bigger window â†’ more it can think about at once  
- Smaller window â†’ more it forgets or truncates  

It doesnâ€™t affect the modelâ€™s intelligence, but it dramatically affects **how much** it can reason over.

---
### ğŸ“Š **Context Window Comparison Across Major Models**

Below is a highâ€‘level comparison of typical context window sizes across GPT, Claude, Gemini, Llama, and Mistral.  
(Exact numbers vary by version, but these are the widely referenced ranges.)

---

#### ğŸ”µ **GPT (OpenAI)**
GPT models have steadily expanded their windows.

| Model | Typical Context Window |
|------|-------------------------|
| GPTâ€‘3.5 | ~4k â€“ 16k tokens |
| GPTâ€‘4 | ~8k â€“ 32k tokens |
| GPTâ€‘4 Turbo | ~128k tokens |
| GPTâ€‘4.1 / GPTâ€‘4o family | ~128k tokens (common) |

**Strength:** Stable longâ€‘context performance, strong compression.  
**Note:** GPT models often *summarize older context* to stay within limits.

---

#### ğŸŸ£ **Claude (Anthropic)**
Claude is the **longâ€‘context leader**.

| Model | Typical Context Window |
|------|-------------------------|
| Claude 2 | 100k tokens |
| Claude 2.1 | 200k tokens |
| Claude 3 Opus/Sonnet/Haiku | 200k tokens |
| Claude 3.5 Sonnet | 200k tokens |
| Claude 3.7 | 200k tokens |

**Strength:** Exceptional longâ€‘document recall and reasoning.  
**Note:** Claude is known for *highâ€‘fidelity retrieval* even near the window limit.

---

#### ğŸŸ¡ **Gemini (Google DeepMind)**
Gemini models are designed for multimodal + longâ€‘context tasks.

| Model | Typical Context Window |
|------|-------------------------|
| Gemini 1.0 Pro | ~32k tokens |
| Gemini 1.5 Pro | **1M tokens** |
| Gemini 1.5 Flash | **1M tokens** |
| Gemini 2.0 | 1M+ tokens (varies by tier) |

**Strength:** Massive windows (up to 1 million tokens).  
**Note:** Geminiâ€™s longâ€‘context performance is optimized for multimodal (video, audio, images).

---

#### ğŸŸ¢ **Llama (Meta)**
Openâ€‘source models with growing context windows.

| Model | Typical Context Window |
|------|-------------------------|
| Llama 2 | 4k â€“ 32k tokens |
| Llama 3 | 8k â€“ 128k tokens |
| Llama 3.1 | 128k tokens |
| Llama 3.2 | 128k tokens |

**Strength:** Flexible and extendable (rope scaling).  
**Note:** Community variants often push windows to 256kâ€“1M, but performance varies.

---

#### ğŸŸ  **Mistral (Mistral AI)**

Mistral focuses on efficiency and longâ€‘context scaling.

| Model | Typical Context Window |
|------|-------------------------|
| Mistral 7B | 8k tokens |
| Mixtral 8x7B | 32k tokens |
| Mixtral 8x22B | 64k tokens |
| Mistral Large | 128k tokens |

**Strength:** Strong performance per parameter + efficient longâ€‘context.  
**Note:** MoE architecture helps maintain speed even with larger windows.

---

#### ğŸ§­ **How They Compare at a Glance**

| Model Family | Typical Context Window | Notes |
|--------------|------------------------|-------|
| **GPT** | 32kâ€“128k | Strong reasoning + stable longâ€‘context |
| **Claude** | 200k | Best longâ€‘context recall + accuracy |
| **Gemini** | **1M** | Largest windows available |
| **Llama** | 8kâ€“128k | Openâ€‘source, extendable |
| **Mistral** | 8kâ€“128k | Efficient MoE scaling |

---

### ğŸ§© **Which Models Handle Long Context Best?**

###$ ğŸ¥‡ **Gemini 1.5 Pro / Flash**  

Unmatched raw window size (1M tokens).

#### ğŸ¥ˆ **Claude 3.x**  

Best *quality* of longâ€‘context reasoning and retrieval.

#### ğŸ¥‰ **GPTâ€‘4.1 / GPTâ€‘4o**  

Strong balance of reasoning + longâ€‘context stability.

#### ğŸŸ¦ **Llama & Mistral**  

Great for openâ€‘source deployments, but smaller windows unless extended.

---

### ğŸ§  **1. Reasoning models use the context window as *workspace*, not just memory**

Traditional LLMs treat the context window as:

- input text  
- conversation history  
- output tokens  

Reasoning models treat it as:

- **scratchpad**  
- **planning space**  
- **intermediate reasoning buffer**  
- **selfâ€‘reflection area**  

They generate far more internal tokens (deliberate steps) before producing the final answer.

**Effect:**  

Reasoning models â€œthink inside the window,â€ so they need more room for internal chains of thought.

---

#### ğŸ” **2. They generate *internal reasoning tokens* that count toward the window**

Models like:

- OpenAI o1  
- DeepSeekâ€‘R1  
- QwQâ€‘32B  
- Gemini Flash Thinking  
- Claude Thinking models  

â€¦all produce **hidden reasoning traces** before giving the final answer.

These internal steps:

- are not shown to the user  
- still consume tokens  
- reduce available space for user input  
- require larger windows to maintain coherence  

This is why reasoning models often have:

- higher token usage  
- slower responses  
- larger minimum context requirements  

---

#### ğŸ§© **3. They rely heavily on *longâ€‘range dependencies***  

Reasoning models frequently need to:

- refer back to earlier parts of the prompt  
- maintain multiâ€‘step logic  
- track variables, constraints, and assumptions  
- preserve intermediate results  

This requires:

- **stable longâ€‘context attention**  
- **less degradation near the window limit**  
- **better compression of earlier tokens**  

Reasoning models are trained to maintain fidelity across long spans of text.

---

#### âš™ï¸ **4. They compress and summarize context more aggressively**

To free up space for reasoning, these models:

- summarize earlier parts of the conversation  
- compress irrelevant details  
- retain only the logical structure  
- drop stylistic or redundant content  

This is why reasoning models often feel more â€œfocusedâ€ or â€œstructured.â€

Theyâ€™re optimizing the window for **thinking**, not **chatting**.

---

#### ğŸ”„ **5. They loop internally â€” using the window for iterative refinement**

Reasoning models often perform:

- multiâ€‘pass reasoning  
- selfâ€‘critique  
- plan â†’ evaluate â†’ revise cycles  

Each cycle consumes tokens.

This is fundamentally different from classic LLMs, which generate output in a single forward pass.

---

#### ğŸ“ **6. They require larger context windows to reach peak performance**

Because reasoning models use the window as a workspace, they benefit from:

- 128k  
- 200k  
- 1M token windows  

A reasoning model with a small window is like a mathematician with a tiny notepad.

---

## ğŸ§  Internal Reasoning Tokens

Internal reasoning tokens are one of the most important â€” and least visible â€” innovations behind modern reasoningâ€‘optimized models. Theyâ€™re the hidden â€œscratch workâ€ the model performs before giving you an answer.

Internal reasoning tokens are **tokens the model generates for itself**, not for the user.  
They represent the modelâ€™s *private chain of thought* â€” the intermediate steps it uses to:

- break down a problem  
- explore options  
- check its own work  
- revise incorrect steps  
- plan multiâ€‘step solutions  

These tokens **never appear in the final output**, but they still count toward the context window.

---

### ğŸ” Why They Exist

Classic LLMs generate answers in a single forward pass.  
Reasoning models do something different:

> They generate *internal* text that helps them think before they speak.

This internal text is where the model:

- decomposes the problem  
- tries multiple approaches  
- evaluates partial solutions  
- rejects bad reasoning  
- converges on a final answer  

Itâ€™s the AI equivalent of scratch paper.

---

### ğŸ§© How Internal Reasoning Tokens Flow Through the Model

A simplified view:

```txt
User Prompt
   â†“
Model generates hidden reasoning tokens
   â†“
Model evaluates and refines those tokens
   â†“
Model produces final answer (visible to user)
```

Those hidden tokens might include:

- stepâ€‘byâ€‘step logic  
- intermediate calculations  
- hypotheses  
- selfâ€‘critique  
- alternative paths  
- summaries of earlier reasoning  

Theyâ€™re not shown, but they shape the final output.

---

### âš™ï¸ **Where They Live in the Context Window**

Internal reasoning tokens **consume part of the context window**, just like user input.

Example:

- Model has a 128k context window  
- User prompt uses 10k tokens  
- Model may generate 20kâ€“40k internal reasoning tokens  
- Remaining space is used for the final answer  

This is why reasoning models often need **larger context windows** than standard LLMs.

---

### ğŸ”„ They Enable Multiâ€‘Pass Thinking

Reasoning models donâ€™t just generate internal tokens once.  
They often loop:

1. Generate reasoning tokens  
2. Evaluate them  
3. Rewrite or refine them  
4. Try alternative paths  
5. Produce final answer  

This iterative refinement is what gives reasoning models:

- deeper logic  
- fewer hallucinations  
- better math  
- stronger planning  
- more consistent answers  

---

### ğŸ§  Why You Donâ€™t See Them

Internal reasoning tokens are hidden because:

- they can be messy  
- they may contain false starts  
- they may include incorrect intermediate steps  
- theyâ€™re not meant to be consumed by humans  

You only see the polished final answer.

---

### ğŸ§­ Internal Reasoning Tokens Clean Mental Model

#### Internal reasoning tokens = the modelâ€™s scratchpad.

- **Tokens** = the pieces of text  
- **Embeddings** = the numerical meaning of those pieces  
- **Activations** = the modelâ€™s realâ€‘time thinking  
- **Parameters** = the modelâ€™s longâ€‘term knowledge  
- **Internal reasoning tokens** = the modelâ€™s private notes while solving the problem  

Theyâ€™re the bridge between raw intelligence and the final answer.

---

## Context Windows and Retrieval (RAG)

Context windows and Retrievalâ€‘Augmented Generation (RAG) work together in a way thatâ€™s almost architectural: the context window is the **workspace**, and RAG is the **supply chain** feeding that workspace. Once you see how they interact, the strengths and limitations of longâ€‘context models become much clearer.

---

### ğŸ§  1. The Context Window Sets the Hard Limit

A model can only â€œthink overâ€ the tokens inside its context window.  
RAG doesnâ€™t bypass this limit â€” it **feeds** the window.

So if a model has a 128k window:

- your prompt  
- retrieved documents  
- system instructions  
- internal reasoning tokens  
- the modelâ€™s output  

â€¦all must fit inside that 128k.

RAG is powerful, but it still has to play inside the boundaries of the window.

---

### ğŸ“¥ 2. RAG Decides *What* Goes Into the Window

RAGâ€™s job is to **retrieve only the most relevant chunks** from an external knowledge base and insert them into the prompt.

This means:

- the model doesnâ€™t need to store everything in parameters  
- the context window becomes a curated, onâ€‘demand memory buffer  
- irrelevant information stays out, preserving space  

RAG is essentially a **filter** that protects the context window from overload.

---

### ğŸ§© 3. Chunking Strategy Determines How Much Fits

Because the window is finite, RAG pipelines break documents into **chunks**.

Chunk size affects:

- recall  
- precision  
- context window usage  
- hallucination risk  

Examples:

- **Small chunks (200â€“500 tokens)** â†’ more precise retrieval, but more chunks  
- **Large chunks (1kâ€“4k tokens)** â†’ richer context, but fewer can fit in the window  

Choosing chunk size is a balancing act between **context richness** and **window capacity**.

---

### ğŸ” 4. RAG Uses the Window for Grounding, Not Reasoning

RAG fills the window with **facts**.  
The model uses its parameters + reasoning tokens to interpret those facts.

So the window becomes:

- a temporary knowledge store  
- a grounding buffer  
- a reference sheet  

The modelâ€™s reasoning happens *on top of* the retrieved context.

---

### ğŸ”„ 5. Long Context Models Reduce RAG Load

Models with huge windows (Gemini 1.5, Claude 3.x) can:

- ingest entire documents  
- reduce chunking complexity  
- require fewer retrieval passes  
- maintain more global context  

This shifts RAG from â€œretrieve small piecesâ€ to â€œretrieve entire sectionsâ€.

But even with millionâ€‘token windows, RAG still matters because:
- retrieval improves relevance  
- retrieval reduces noise  
- retrieval avoids wasting window space  

Long context doesnâ€™t replace RAG â€” it **amplifies** it.

---

### âš™ï¸ 6. RAG Pipelines Often Use Multiâ€‘Stage Retrieval to Fit the Window

To avoid overflowing the window, modern RAG systems use:

- vector search  
- reranking  
- summarization  
- compression  
- deduplication  

This ensures only the most relevant content enters the window.

Think of it as:
**RAG = bouncer  
Context window = VIP room**

Only the best content gets in.

---

### ğŸ§  7. Reasoning Models Use the Window Differently

Reasoningâ€‘optimized models (o1â€‘style, DeepSeekâ€‘R1, Claude Thinking) generate **internal reasoning tokens** that also consume window space.

This means:

- RAG must leave room for the model to think  
- too much retrieved text can choke the reasoning process  
- retrieval must be more selective for reasoning models  

RAG for reasoning models is more like **precision surgery** than bulk retrieval.

---

### ğŸ§­ Context Window and RAG Clean Mental Model

- Context window = workspace
- RAG = the system that fills the workspace with relevant information
- Reasoning tokens = the modelâ€™s internal thinking inside that workspace

They all share the same finite space, so good RAG design is about **maximizing relevance per token**.

---
